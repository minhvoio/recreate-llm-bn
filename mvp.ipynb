{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf1e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemma3n:e4b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca77d64",
   "metadata": {},
   "source": [
    "# User Query Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ded5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "def answer_this_prompt(prompt, stream=False, model=MODEL, temperature=0, format=None):\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_new_tokens\": 50, # only when stream = False work\n",
    "        \"format\": format\n",
    "    }\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    endpoint = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    # Send the POST request with streaming enabled\n",
    "    with requests.post(endpoint, headers=headers, json=payload, stream=True) as response:\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                # Process the response incrementally\n",
    "                full_response = \"\"\n",
    "                for line in response.iter_lines(decode_unicode=True):\n",
    "                    if line.strip():  # Skip empty lines\n",
    "                        response_json = json.loads(line)\n",
    "                        chunk = response_json.get(\"response\", \"\")\n",
    "                        full_response += chunk\n",
    "                        \n",
    "                        # Render the response as Markdown\n",
    "                        if stream:\n",
    "                            clear_output(wait=True)\n",
    "                            display(Markdown(full_response))\n",
    "                        \n",
    "                return full_response\n",
    "            except json.JSONDecodeError as e:\n",
    "                return \"Failed to parse JSON: \" + str(e)\n",
    "        else:\n",
    "            return \"Failed to retrieve response: \" + str(response.status_code)\n",
    "        \n",
    "def multiple_answer_this_prompt(prompt, stream=False, model=MODEL, temperature=0, format=None, n_answers=1):\n",
    "    answers = []\n",
    "    for _ in range(n_answers):\n",
    "        answer = answer_this_prompt(prompt, stream=stream, model=model, temperature=temperature, format=format)\n",
    "        answers.append(answer)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2f7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "ans = answer_this_prompt(\"What is the Big Bang theory?\", stream=True)\n",
    "print(\"------------------------\")\n",
    "print(type(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_path = \"/nets/collection/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f69191fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fromNode='Lung' toNode='Cancer (Lung Cancer)'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Query(BaseModel):\n",
    "  fromNode: str\n",
    "  toNode: str\n",
    "\n",
    "prompt = \"\"\"Is Lung connected to Cancer?\"\"\"\n",
    "ans = answer_this_prompt(prompt, format=Query.model_json_schema())\n",
    "query = Query.model_validate_json(ans)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a3902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
